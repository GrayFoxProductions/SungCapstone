{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline of Immigration, Temperature, US Demographics\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import configparser\n",
    "import datetime, time\n",
    "import datetime as dt\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear, lit, explode, regexp_extract, isnull, desc, when, sum, to_date, desc, regexp_replace, count, to_timestamp, date_format\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import date_add as d_add\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import GroupedData, HiveContext\n",
    "\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "import importlib\n",
    "import tools\n",
    "import etl_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Scope the Project and Gather Data\n",
    "\n",
    "## Project Scope \n",
    "<hr></hr>\n",
    "\n",
    "To create the analytics database, the following steps will be carried out:\n",
    "* Use Spark to load the data into dataframes.\n",
    "* Exploratory data analysis of I94 immigration dataset to identify missing values and strategies for data cleaning.\n",
    "* Exploratory data analysis of demographics dataset to identify missing values and strategies for data cleaning.\n",
    "* Exploratory data analysis of global land temperatures by city dataset to identify missing values and strategies for data cleaning.\n",
    "* Perform data cleaning functions on all the datasets.\n",
    "* Create dimension tables.\n",
    "    * Create immigration calendar dimension table from I94 immigration dataset, this table links to the fact table through the arrdate field.\n",
    "    * Create country dimension table from the I94 immigration and the global temperatures dataset. The global land temperatures data was aggregated at country level. The table links to the fact table through the country of residence code allowing analysts to understand correlation between country of residence climate and immigration to US states. \n",
    "    * Create usa demographics dimension table from the us cities demographics data. This table links to the fact table through the state code field. \n",
    "    \n",
    "* Create fact table from the clean I94 immigration dataset and the visa_type dimension.\n",
    "\n",
    "<p>\n",
    "The technology used in this project is <b>Amazon S3, Apache Spark</b>. Data will be read and staged from the customers repository using Spark.\n",
    "</p>\n",
    "\n",
    "While the whole project has been implemented on this notebook, provisions has been made to run the ETL on a spark cluster through etl.py. The etl.py script reads data from S3 and creates fact and dimesion tables through Spark that are loaded back into S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load and Descriptions\n",
    "---\n",
    "#### I94 Immigration Data Description \n",
    "<hr style=\"background-color: #b7d0e2;\"/> \n",
    "\n",
    "This data comes from the US National Tourism and Trade Office. In the past all foreign visitors to the U.S. arriving via air or sea were required to complete paper Customs and Border Protection Form I-94 Arrival/Departure Record or Form I-94W Nonimmigrant Visa Waiver Arrival/Departure Record and this dataset comes from this forms. \n",
    "\n",
    "This dataset forms the core of the data warehouse and the customer repository has a years worth of data for the year 2016 and the dataset is divided by month. For this project the data is in a folder located at ../../data/18-83510-I94-Data-2016/. Each months data is stored in an SAS binary database storage format <i>sas7bdat</i>. For this project we have chosen going to work with data for the month of April. However, the data extraction, transformation and loading utility functions have been designed to work with any month's worth of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Immigration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1) Full dataset\n",
    "# Load the immigration dataset using workspace folder in parquet format & create dataframe\n",
    "df_immigration =spark.read.load('./sas_data')\n",
    "\n",
    "\n",
    "# Option 2) Smaller sample immigration dataset to use for testing purposes\n",
    "#file_name = \"immigration_data_sample.csv\"\n",
    "#df_immigration = spark.read.csv(file_name, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed without error\n"
     ]
    }
   ],
   "source": [
    "# Option used when reading the DATA folder......see differences\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "df_immigration =spark.read.load('./sas_data')\n",
    "print(\"Completed without error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with Option 2 only to drop extra unused column when using smaller immigration sample csv file\n",
    "df_immigration=df_immigration.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of records\n",
    "df_immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0      1.0   \n",
       "1  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0      1.0   \n",
       "2  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0      1.0   \n",
       "3  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0      1.0   \n",
       "4   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0      3.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      HI  20573.0   ...        None        M   1955.0  07202016      F   \n",
       "1      TX  20568.0   ...        None        M   1990.0  10222016      M   \n",
       "2      FL  20571.0   ...        None        M   1940.0  07052016      M   \n",
       "3      CA  20581.0   ...        None        M   1991.0  10272016      M   \n",
       "4      NY  20553.0   ...        None        M   1997.0  07042016      F   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      JL  5.658267e+10  00782       WT  \n",
       "1   None     *GA  9.436200e+10  XBLNG       B2  \n",
       "2   None      LH  5.578047e+10  00464       WT  \n",
       "3   None      QR  9.478970e+10  00739       B2  \n",
       "4   None    None  4.232257e+10   LAND       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 5 records\n",
    "df_immigration.limit(5).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid',\n",
       " 'i94yr',\n",
       " 'i94mon',\n",
       " 'i94cit',\n",
       " 'i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'i94addr',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'dtadfile',\n",
       " 'visapost',\n",
       " 'occup',\n",
       " 'entdepa',\n",
       " 'entdepd',\n",
       " 'entdepu',\n",
       " 'matflag',\n",
       " 'biryear',\n",
       " 'dtaddto',\n",
       " 'gender',\n",
       " 'insnum',\n",
       " 'airline',\n",
       " 'admnum',\n",
       " 'fltno',\n",
       " 'visatype']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all columns\n",
    "df_immigration.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Immigration Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">cicid</td><td class=\"tg-0pky\">Unique record ID</td>\n",
    " <tr><td class=\"tg-0pky\">i94yr</td><td class=\"tg-0pky\">4 digit year</td>\n",
    " <tr><td class=\"tg-0pky\">i94mon</td><td class=\"tg-0pky\">Numeric month</td>\n",
    " <tr><td class=\"tg-0pky\">i94cit</td><td class=\"tg-0pky\">3 digit code for traveler's birth country</td>\n",
    " <tr><td class=\"tg-0pky\">i94res</td><td class=\"tg-0pky\">3 digit code for traveler's country of residence </td>\n",
    " <tr><td class=\"tg-0pky\">i94port</td><td class=\"tg-0pky\">Port of admission</td>\n",
    " <tr><td class=\"tg-0pky\">arrdate</td><td class=\"tg-0pky\">Arrival Date into the US</td>\n",
    " <tr><td class=\"tg-0pky\">i94mode</td><td class=\"tg-0pky\">Mode of transportation; 1 = Air; 2 = Sea; 3 = Land; 9 = Unknown</td>\n",
    " <tr><td class=\"tg-0pky\">i94addr</td><td class=\"tg-0pky\">US State of arrival</td>\n",
    " <tr><td class=\"tg-0pky\">depdate</td><td class=\"tg-0pky\">Departure Date from the US</td>\n",
    " <tr><td class=\"tg-0pky\">i94bir</td><td class=\"tg-0pky\">Birth Year</td>\n",
    " <tr><td class=\"tg-0pky\">i94visa</td><td class=\"tg-0pky\">Visa codes</td>\n",
    " <tr><td class=\"tg-0pky\">count</td><td class=\"tg-0pky\">Field used for summary statistics</td>\n",
    " <tr><td class=\"tg-0pky\">dtadfile</td><td class=\"tg-0pky\">Character Date Field - Date added to I-94 Files</td>\n",
    " <tr><td class=\"tg-0pky\">visapost</td><td class=\"tg-0pky\">Department of State where Visa was issued </td>\n",
    " <tr><td class=\"tg-0pky\">occup</td><td class=\"tg-0pky\">Occupation that will be conducted in U.S</td>\n",
    " <tr><td class=\"tg-0pky\">entdepa</td><td class=\"tg-0pky\">Arrival Flag</td>\n",
    " <tr><td class=\"tg-0pky\">entdepd</td><td class=\"tg-0pky\">Departure Flag</td>\n",
    " <tr><td class=\"tg-0pky\">entdepu</td><td class=\"tg-0pky\">Update Flag</td>\n",
    " <tr><td class=\"tg-0pky\">matflag</td><td class=\"tg-0pky\">Match flag</td>\n",
    " <tr><td class=\"tg-0pky\">biryear</td><td class=\"tg-0pky\">4 digit year of birth</td>\n",
    " <tr><td class=\"tg-0pky\">dtaddto</td><td class=\"tg-0pky\">Character Date Field; Date to which admitted to U.S.</td>\n",
    " <tr><td class=\"tg-0pky\">gender</td><td class=\"tg-0pky\">Gender</td>\n",
    " <tr><td class=\"tg-0pky\">insnum</td><td class=\"tg-0pky\">INS number</td>\n",
    " <tr><td class=\"tg-0pky\">airline</td><td class=\"tg-0pky\">Arrival Airline</td>\n",
    " <tr><td class=\"tg-0pky\">admnum</td><td class=\"tg-0pky\">Admission Number</td>\n",
    " <tr><td class=\"tg-0pky\">fltno</td><td class=\"tg-0pky\">Arrival Airline Flight number</td>\n",
    " <tr><td class=\"tg-0pky\">visatype</td><td class=\"tg-0pky\">Class of admission</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US City Demographic Data Description \n",
    "<hr style=\"background-color: #b7d0e2;\"/> \n",
    "Describe Demographics Data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data via CSV file in workspace\n",
    "file_name = \"us-cities-demographics.csv\"\n",
    "df_demographics = spark.read.csv(file_name, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of records\n",
    "df_demographics.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 5 records\n",
    "df_demographics.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List out all columns\n",
    "df_demographics.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>US City Demographics Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">City</td><td class=\"tg-0pky\">City Name</td>\n",
    " <tr><td class=\"tg-0pky\">State</td><td class=\"tg-0pky\">State of city</td>\n",
    " <tr><td class=\"tg-0pky\">Median Age</td><td class=\"tg-0pky\">Median age of population</td>\n",
    " <tr><td class=\"tg-0pky\">Male Population</td><td class=\"tg-0pky\">Male Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">Female Population</td><td class=\"tg-0pky\">Female Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">Total Population</td><td class=\"tg-0pky\">Total Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">Number of Veterans</td><td class=\"tg-0pky\">Veteran Population in city</td>\n",
    " <tr><td class=\"tg-0pky\">Foreign Born</td><td class=\"tg-0pky\">Population of residents not born in city</td>\n",
    " <tr><td class=\"tg-0pky\">Average Household Size</td><td class=\"tg-0pky\">Average city household size</td>\n",
    " <tr><td class=\"tg-0pky\">State Code</td><td class=\"tg-0pky\">Code of US State</td>\n",
    " <tr><td class=\"tg-0pky\">Race</td><td class=\"tg-0pky\">Traveler's race</td>\n",
    " <tr><td class=\"tg-0pky\">Count</td><td class=\"tg-0pky\">Count of city's individual per race</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World Temperature Data Description \n",
    "<hr style=\"background-color: #b7d0e2;\"/> \n",
    "Describe Temp data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = spark.read.csv(file_name, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>World Temperature Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">dt</td><td class=\"tg-0pky\">Date</td>\n",
    " <tr><td class=\"tg-0pky\">AverageTemperature</td><td class=\"tg-0pky\">Global average land temperature in celsius</td>\n",
    " <tr><td class=\"tg-0pky\">AverageTemperatureUncertainty</td><td class=\"tg-0pky\">95% confidence interval around the average</td>\n",
    " <tr><td class=\"tg-0pky\">City</td><td class=\"tg-0pky\">City Name</td>\n",
    " <tr><td class=\"tg-0pky\">Country</td><td class=\"tg-0pky\">Country Name</td>\n",
    " <tr><td class=\"tg-0pky\">Latitude</td><td class=\"tg-0pky\">Latitude of City</td>\n",
    " <tr><td class=\"tg-0pky\">Longitude</td><td class=\"tg-0pky\">Longitude of City</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 12 files in the I94 dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i94_apr16_sub.sas7bdat',\n",
       " 'i94_sep16_sub.sas7bdat',\n",
       " 'i94_nov16_sub.sas7bdat',\n",
       " 'i94_mar16_sub.sas7bdat',\n",
       " 'i94_jun16_sub.sas7bdat',\n",
       " 'i94_aug16_sub.sas7bdat',\n",
       " 'i94_may16_sub.sas7bdat',\n",
       " 'i94_jan16_sub.sas7bdat',\n",
       " 'i94_oct16_sub.sas7bdat',\n",
       " 'i94_jul16_sub.sas7bdat',\n",
       " 'i94_feb16_sub.sas7bdat',\n",
       " 'i94_dec16_sub.sas7bdat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of immigration files in the I94 dataset archive\n",
    "files = os.listdir('../../data/18-83510-I94-Data-2016/')\n",
    "print(\"There are a total of {} files in the I94 dataset.\".format(len(files)))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i94_apr16_sub.sas7bdat - dim(bytes): 471990272\n",
      "i94_sep16_sub.sas7bdat - dim(bytes): 569180160\n",
      "i94_nov16_sub.sas7bdat - dim(bytes): 444334080\n",
      "i94_mar16_sub.sas7bdat - dim(bytes): 481296384\n",
      "i94_jun16_sub.sas7bdat - dim(bytes): 716570624\n",
      "i94_aug16_sub.sas7bdat - dim(bytes): 625541120\n",
      "i94_may16_sub.sas7bdat - dim(bytes): 525008896\n",
      "i94_jan16_sub.sas7bdat - dim(bytes): 434176000\n",
      "i94_oct16_sub.sas7bdat - dim(bytes): 556269568\n",
      "i94_jul16_sub.sas7bdat - dim(bytes): 650117120\n",
      "i94_feb16_sub.sas7bdat - dim(bytes): 391905280\n",
      "i94_dec16_sub.sas7bdat - dim(bytes): 523304960\n"
     ]
    }
   ],
   "source": [
    "# Size of the I94 files\n",
    "for file in files:\n",
    "    size = os.path.getsize('{}/{}'.format('../../data/18-83510-I94-Data-2016/', file))\n",
    "    print('{} - dim(bytes): {}'.format(file, size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immigration Data Clean\n",
    "1) Clean the data types from DOUBLE to INTEGER since double is not most useful type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View dataset schema\n",
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "toInt = udf(lambda x: int(x) if x!=None else x, IntegerType())\n",
    "\n",
    "for colname, coltype in df_immigration.dtypes:\n",
    "    if coltype == 'double':\n",
    "        df_immigration = df_immigration.withColumn(colname, toInt(colname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: integer (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: integer (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: integer (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify schema is showing updated data type of INTEGER\n",
    "df_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  Convert depdate's SAS format to datetime format since SAS format are numbers that represent the number of days from Jan 1, 1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert arrdate & depdate to datetime format using udf\n",
    "\n",
    "def convert_to_datetime(date):\n",
    "\n",
    "    if date is not None:\n",
    "        return pd.Timestamp('1960-1-1')+pd.to_timedelta(date, unit='D')\n",
    "convert_to_datetime_udf = udf(convert_to_datetime, DateType())\n",
    "df_immigration = df_immigration.withColumn('arrdate',convert_to_datetime_udf(col('arrdate')))\n",
    "df_immigration = df_immigration.withColumn('depdate',convert_to_datetime_udf(col('depdate')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>HHW</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>1</td>\n",
       "      <td>HI</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1955</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>JL</td>\n",
       "      <td>748099785</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>MCA</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>2016-04-24</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1990</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>*GA</td>\n",
       "      <td>-127284582</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>OGG</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1940</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>LH</td>\n",
       "      <td>-54106415</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-05-07</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1991</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>QR</td>\n",
       "      <td>300415518</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>CHM</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1997</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-627100327</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cicid  i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  4084316   2016       4     209     209     HHW  2016-04-22        1   \n",
       "1  4422636   2016       4     582     582     MCA  2016-04-23        1   \n",
       "2  1195600   2016       4     148     112     OGG  2016-04-07        1   \n",
       "3  5291768   2016       4     297     297     LOS  2016-04-28        1   \n",
       "4   985523   2016       4     111     111     CHM  2016-04-06        3   \n",
       "\n",
       "  i94addr     depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      HI  2016-04-29   ...        None        M     1955  07202016      F   \n",
       "1      TX  2016-04-24   ...        None        M     1990  10222016      M   \n",
       "2      FL  2016-04-27   ...        None        M     1940  07052016      M   \n",
       "3      CA  2016-05-07   ...        None        M     1991  10272016      M   \n",
       "4      NY  2016-04-09   ...        None        M     1997  07042016      F   \n",
       "\n",
       "  insnum airline     admnum  fltno visatype  \n",
       "0   None      JL  748099785  00782       WT  \n",
       "1   None     *GA -127284582  XBLNG       B2  \n",
       "2   None      LH  -54106415  00464       WT  \n",
       "3   None      QR  300415518  00739       B2  \n",
       "4   None    None -627100327   LAND       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming arrdate & depdate is now in yyyy-mm-dd format.\n",
    "df_immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) i94 Null Check, missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Raw, code to find if any columns have nulls\n",
    "df_immigration.select(*[\n",
    "    (\n",
    "        F.count(F.when((F.isnan(c) | F.col(c).isNull()), c)) if t not in (\"timestamp\", \"date\")\n",
    "        else F.count(F.when(F.col(c).isNull(), c))\n",
    "    ).alias(c)\n",
    "    for c, t in df_immigration.dtypes if c in df_immigration.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>i94 Null Analysis </u>  \n",
    "*entepu(99% empty)= Update flag;apprehended,overstayed, or adjusted due to permanent residence.  \n",
    "*insum(96% empty)= INS number  \n",
    "*Occup(99% empty)= Occupation to be conducted in US.  \n",
    "  \n",
    "These columns contain >90% empty values thus will be removed from the i94 data set.  \n",
    "Remaining columns had nulls ranging from 1% to 60%, which still contain a solid amount of data thus will included in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the >90% null columns in the i94 dataset\n",
    "cols = ['occup', 'entdepu','insnum']\n",
    "\n",
    "df_new_immigration = df_immigration.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: date (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: integer (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the new schema with the 3 columns dropped\n",
    "df_new_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) i94 Duplicate Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i94 Duplicate check using CICID as identifier since its unique\n",
    "df_final_immigration = df_new_immigration.dropDuplicates(['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_immigration.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> i94 Duplicate Analysis </u>  \n",
    "No duplicates found in i94 dataset.\n",
    "\n",
    "In summary, 3 columns were dropped due to nulls while no rows removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Null check, missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|City|State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race|Count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now checking Demographics for nulls\n",
    "df_demographics.select(*[\n",
    "    (\n",
    "        F.count(F.when((F.isnan(c) | F.col(c).isNull()), c)) if t not in (\"timestamp\", \"date\")\n",
    "        else F.count(F.when(F.col(c).isNull(), c))\n",
    "    ).alias(c)\n",
    "    for c, t in df_demographics.dtypes if c in df_demographics.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>null values</th>\n",
       "      <th>% missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male Population</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female Population</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Number of Veterans</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Foreign-born</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Average Household Size</td>\n",
       "      <td>16</td>\n",
       "      <td>0.553442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   column  null values  % missing\n",
       "3         Male Population            3   0.103770\n",
       "4       Female Population            3   0.103770\n",
       "6      Number of Veterans           13   0.449671\n",
       "7            Foreign-born           13   0.449671\n",
       "8  Average Household Size           16   0.553442"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table showing null columns and how much is null% within that column\n",
    "\n",
    "# View columns with missing data\n",
    "nulls_df = pd.DataFrame(data= df_demographics.toPandas().isnull().sum(), columns=['null values'])\n",
    "nulls_df = nulls_df.reset_index()\n",
    "nulls_df.columns = ['column', 'null values']\n",
    "\n",
    "# calculate % missing values\n",
    "nulls_df['% missing'] = 100*nulls_df['null values']/df_demographics.count()\n",
    "nulls_df[nulls_df['% missing']>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Demographics null analysis</u>  \n",
    "*Male Population(3 empty)= Male population of city  \n",
    "*Female Population(3 empty)= Female population of city  \n",
    "*Number of Veterans(13 empty)= Veteran population in city  \n",
    "*Foreign-born(13 empty)= Population of residents not born in city  \n",
    "*Average Household Size(16 empty)= Average household size of city  \n",
    "  \n",
    "5 columns contained nulls and those columns have less than only 1% empty values.\n",
    "So will keep columns intact and just remove the ROWS with nulls since columns still have solid amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Demographic dataset dropped with missing values: 16\n"
     ]
    }
   ],
   "source": [
    "# drop ROWS(not columns) with missing values\n",
    "subset_cols = [\n",
    "    'Male Population',\n",
    "    'Female Population',\n",
    "    'Number of Veterans',\n",
    "    'Foreign-born',\n",
    "    'Average Household Size'\n",
    "]\n",
    "    \n",
    "df_new_demographics = df_demographics.dropna(subset=subset_cols)\n",
    "    \n",
    "rows_dropped = df_demographics.count()-df_new_demographics.count()\n",
    "print(\"Rows in Demographic dataset dropped with missing values: {}\".format(rows_dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Demographic Duplicate check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Demographic dataset dropped due to duplicate row entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Duplicate check for demography using city + state + state code + race, \n",
    "# These unique identifiers ensures row entry is indeed a duplicate\n",
    "\n",
    "df_final_demographics = df_new_demographics.drop_duplicates(subset=['City', 'State', 'State Code', 'Race'])\n",
    "rows_dropped = df_new_demographics.count()-df_final_demographics.count()\n",
    "print(\"Rows in Demographic dataset dropped due to duplicate row entries: {}\".format(rows_dropped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Demographics Duplicate Analysis</u>  \n",
    "Using unique identifiers of (City, State, State Code, Race), no duplicate row entries were found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Data Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Convert dt column datatype: timestamp -> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_temperature = df_temperature.withColumn(\"dt\",col(\"dt\").cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Null check, missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "| dt|AverageTemperature|AverageTemperatureUncertainty|City|Country|Latitude|Longitude|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "|  0|            364130|                       364130|   0|      0|       0|        0|\n",
      "+---+------------------+-----------------------------+----+-------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final null check on 3rd table: World Temperature\n",
    "\n",
    "df_new_temperature.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_new_temperature.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in Temp dataframe before null removal: 8,599,212\n",
      "Rows in Temperature dataset dropped with missing values: 364130\n",
      "Total records in Temp dataframe after null removal: 8,235,082\n"
     ]
    }
   ],
   "source": [
    "# Since only 4% of the Average Temperature column is null, the column is worth keeping\n",
    "# So drop the row entries with the missing values in Ave Temp\n",
    "\n",
    "total_records = df_new_temperature.count()\n",
    "print(f'Total records in Temp dataframe before null removal: {total_records:,}')    \n",
    "    \n",
    "df_null_temperature = df_new_temperature.dropna(subset=['AverageTemperature'])\n",
    "    \n",
    "rows_dropped = df_new_temperature.count()-df_null_temperature.count()\n",
    "print(\"Rows in Temperature dataset dropped with missing values: {}\".format(rows_dropped))\n",
    "\n",
    "total_records2 = df_null_temperature.count()\n",
    "print(f'Total records in Temp dataframe after null removal: {total_records2:,}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Temperature Null Analysis</u>  \n",
    "Since only 4% of the Average Temperature column is null, the column is worth keeping \n",
    "\n",
    "So drop the row entries with the missing values in Ave Temp.\n",
    "\n",
    "364,130 rows contained missing Ave Temp and are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Temperature Duplicate Check & Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in Temperature dataset dropped due to duplicate row entries: 44299\n",
      "Total records in Temperature dataset after duplicate clean:8190783\n"
     ]
    }
   ],
   "source": [
    "# Need a unique identifier that isolates duplicates in Temp data:  use dt + city + country\n",
    "\n",
    "df_final_temperature = df_null_temperature.drop_duplicates(subset=['dt','City','Country'])\n",
    "rows_dropped = df_null_temperature.count()-df_final_temperature.count()\n",
    "print(\"Rows in Temperature dataset dropped due to duplicate row entries: {}\".format(rows_dropped))\n",
    "\n",
    "print(\"Total records in Temperature dataset after duplicate clean:{}\".format(df_final_temperature.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Temperature Dataset Duplicate Analysis</u>  \n",
    "Using unique identifiers of (dt, city, country), 44,299 duplicate row entries were found and dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before creating tables in jupyter test environment,\n",
    "# Create a temporary Parquet directory for tables to be stored locally for notebook purposes\n",
    "output_data = \"tables/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create timedate dimension table\n",
    "Unique identifier created using Monotonically increasing ID and added as new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_immigration_time(df, output_data):\n",
    "    \"\"\"This function creates an immigration time table based on arrival date\n",
    "    \n",
    "    params \n",
    "        df:          spark dataframe of immigration events\n",
    "        output_data: path to write dimension dataframe to\n",
    "    \"\"\"\n",
    "    \n",
    "    # create initial calendar df from arrdate column\n",
    "    time_df = df.select(['arrdate'])\n",
    "    \n",
    "    # expand df by adding other calendar columns\n",
    "    time_df = time_df.withColumn('arrival_day', dayofmonth('arrdate'))\n",
    "    time_df = time_df.withColumn('arrival_week', weekofyear('arrdate'))\n",
    "    time_df = time_df.withColumn('arrival_month', month('arrdate'))\n",
    "    time_df = time_df.withColumn('arrival_year', year('arrdate'))\n",
    "    time_df = time_df.withColumn('arrival_weekday', dayofweek('arrdate'))\n",
    "\n",
    "    # create an id field in calendar df\n",
    "    time_df = time_df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    # write the calendar dimension to parquet file\n",
    "    partition_columns = ['arrival_year', 'arrival_month', 'arrival_week']\n",
    "    time_df.write.parquet(output_data + \"time\", partitionBy=partition_columns, mode=\"overwrite\")\n",
    "    \n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>arrival_week</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_weekday</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrdate  arrival_day  arrival_week  arrival_month  arrival_year  \\\n",
       "0  2016-04-13           13            15              4          2016   \n",
       "1  2016-04-25           25            17              4          2016   \n",
       "2  2016-04-08            8            14              4          2016   \n",
       "3  2016-04-25           25            17              4          2016   \n",
       "4  2016-04-02            2            13              4          2016   \n",
       "\n",
       "   arrival_weekday  id  \n",
       "0                4   0  \n",
       "1                2   1  \n",
       "2                6   2  \n",
       "3                2   3  \n",
       "4                7   4  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df = create_immigration_time(df_final_immigration, output_data)\n",
    "time_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create country dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method creates a country code --> country name dictionary from the SAS file, then use the dictionary \n",
    "# to covert to a CSV file\n",
    "\n",
    "# Opening the SAS Label Descriptions File \n",
    "with open(\"I94_SAS_Labels_Descriptions.SAS\") as sas_file:\n",
    "        file_contents = sas_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting country code from the SAS file and splitting the code \n",
    "\n",
    "dictcountry_code = {}\n",
    "\n",
    "# For loop for in input country variable in the file contents of the SAS file\n",
    "for input_countries in file_contents[10:298]:\n",
    "    # Splitting the contents\n",
    "    pair = input_countries.split('=')\n",
    "    # Code, country pair values\n",
    "    code, country = pair[0].strip(), pair[1].strip().strip(\"'\")\n",
    "    # storing the final results\n",
    "    dictcountry_code[code] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code         Name\n",
       "0  236  AFGHANISTAN\n",
       "1  101      ALBANIA\n",
       "2  316      ALGERIA\n",
       "3  102      ANDORRA\n",
       "4  324       ANGOLA"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the country code and country name from the list into the dataframe\n",
    "df_dictcountry_code = pd.DataFrame(list(dictcountry_code.items()), columns=['code', 'Name'])\n",
    "\n",
    "# Previewing the 5 rows from country code dataframe\n",
    "df_dictcountry_code.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataframe to CSV file\n",
    "df_dictcountry_code.to_csv('i94res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country(df, temp_df, output_data):\n",
    "    \"\"\"This function creates a country dimension from the immigration and global land temperatures data.\n",
    "    \n",
    "    :param df: spark dataframe of immigration events\n",
    "    :temp_df: spark dataframe of global land temperatures data.\n",
    "    :param output_data: path to write dimension dataframe to\n",
    "    :return: spark dataframe representing calendar dimension\n",
    "    \"\"\"\n",
    "    # get the aggregated temperature data\n",
    "    agg_temp = tools.aggregate_temperature_data(temp_df).toPandas()\n",
    "    # load the i94res to country mapping data\n",
    "    mapping_codes = pd.read_csv('i94res.csv')\n",
    "    \n",
    "    @udf('string')\n",
    "    def get_country_average_temperature(name):\n",
    "        print(\"Processing: \", name)\n",
    "        avg_temp = agg_temp[agg_temp['Country']==name]['average_temperature']\n",
    "        \n",
    "        if not avg_temp.empty:\n",
    "            return str(avg_temp.iloc[0])\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @udf()\n",
    "    def get_country_name(code):\n",
    "        name = mapping_codes[mapping_codes['code']==code]['Name'].iloc[0]\n",
    "        \n",
    "        if name:\n",
    "            return name.title()\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    # select i94res column\n",
    "    dim_df = df.select(['i94res']).distinct() \\\n",
    "                .withColumnRenamed('i94res', 'country_code')\n",
    "    \n",
    "    # create country_name column\n",
    "    dim_df = dim_df.withColumn('country_name', get_country_name(dim_df.country_code))\n",
    "    \n",
    "    # create average_temperature column\n",
    "    dim_df = dim_df.withColumn('average_temperature', get_country_average_temperature(dim_df.country_name))\n",
    "    \n",
    "    # write the dimension to a parquet file\n",
    "    dim_df.write.parquet(output_data + \"country\", mode=\"overwrite\")\n",
    "    \n",
    "    return dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>average_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>Burma</td>\n",
       "      <td>26.0168399893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>516</td>\n",
       "      <td>Trinidad And Tobago</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251</td>\n",
       "      <td>Israel</td>\n",
       "      <td>19.0076965915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>26.5726805482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>513</td>\n",
       "      <td>Barbados</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_code          country_name average_temperature\n",
       "0           243                 Burma       26.0168399893\n",
       "1           516   Trinidad And Tobago                None\n",
       "2           251                Israel       19.0076965915\n",
       "3           296  United Arab Emirates       26.5726805482\n",
       "4           513              Barbados                None"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_df = create_country(df_final_immigration, df_final_temperature, output_data)\n",
    "country_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Demographics dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demographics(df, output_data):\n",
    "    \"\"\"This function creates a us demographics dimension table from the us cities demographics data.\n",
    "    \n",
    "    params \n",
    "        df: spark dataframe of US demographics survey data\n",
    "        output_data: path to write dimension dataframe to\n",
    "    \"\"\"\n",
    "    dim_df = df.withColumnRenamed('Median Age','median_age') \\\n",
    "            .withColumnRenamed('Male Population', 'male_population') \\\n",
    "            .withColumnRenamed('Female Population', 'female_population') \\\n",
    "            .withColumnRenamed('Total Population', 'total_population') \\\n",
    "            .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "            .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "            .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "            .withColumnRenamed('State Code', 'state_code')\n",
    "    # Add an id column\n",
    "    dim_df = dim_df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    dim_df.write.parquet(output_data + \"demographics\", mode=\"overwrite\")\n",
    "    \n",
    "    return dim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wilmington</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>52346</td>\n",
       "      <td>63601</td>\n",
       "      <td>115947</td>\n",
       "      <td>5908</td>\n",
       "      <td>7401</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>3152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>Florida</td>\n",
       "      <td>35.3</td>\n",
       "      <td>175517</td>\n",
       "      <td>193511</td>\n",
       "      <td>369028</td>\n",
       "      <td>20636</td>\n",
       "      <td>58795</td>\n",
       "      <td>2.47</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>95154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gastonia</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>36.9</td>\n",
       "      <td>35527</td>\n",
       "      <td>39023</td>\n",
       "      <td>74550</td>\n",
       "      <td>3537</td>\n",
       "      <td>5715</td>\n",
       "      <td>2.67</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2788</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>Texas</td>\n",
       "      <td>33.9</td>\n",
       "      <td>50422</td>\n",
       "      <td>53283</td>\n",
       "      <td>103705</td>\n",
       "      <td>4813</td>\n",
       "      <td>8225</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City           State  median_age  male_population  female_population  \\\n",
       "0      Quincy   Massachusetts        41.0            44129              49500   \n",
       "1  Wilmington  North Carolina        35.5            52346              63601   \n",
       "2       Tampa         Florida        35.3           175517             193511   \n",
       "3    Gastonia  North Carolina        36.9            35527              39023   \n",
       "4       Tyler           Texas        33.9            50422              53283   \n",
       "\n",
       "   total_population  number_of_veterans  foreign_born  average_household_size  \\\n",
       "0             93629                4147         32935                    2.39   \n",
       "1            115947                5908          7401                    2.24   \n",
       "2            369028               20636         58795                    2.47   \n",
       "3             74550                3537          5715                    2.67   \n",
       "4            103705                4813          8225                    2.59   \n",
       "\n",
       "  state_code                               Race  Count  id  \n",
       "0         MA                              White  58723   0  \n",
       "1         NC                              Asian   3152   1  \n",
       "2         FL                 Hispanic or Latino  95154   2  \n",
       "3         NC                              Asian   2788   3  \n",
       "4         TX  American Indian and Alaska Native   1057   4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df = create_demographics(df_final_demographics, output_data)\n",
    "demographics_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Visatype dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visa_type(df, output_data):\n",
    "    \"\"\"This function creates a visa type dimension from the immigration data.\n",
    "    \n",
    "    params:\n",
    "        df:          spark dataframe of immigration events\n",
    "        output_data: path to write dimension dataframe to\n",
    "    \"\"\"\n",
    "    # create visatype df from visatype column, distinct because need to classify each type only once\n",
    "    visatype_df = df.select(['visatype']).distinct()\n",
    "    \n",
    "    # add an id column\n",
    "    visatype_df = visatype_df.withColumn('visa_type_key', monotonically_increasing_id())\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    visatype_df.write.parquet(output_data + \"visatype\", mode=\"overwrite\")\n",
    "    \n",
    "    return visatype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visatype</th>\n",
       "      <th>visa_type_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F2</td>\n",
       "      <td>103079215104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>369367187456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1</td>\n",
       "      <td>498216206336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WB</td>\n",
       "      <td>738734374912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>747324309504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visatype  visa_type_key\n",
       "0       F2   103079215104\n",
       "1       B2   369367187456\n",
       "2       F1   498216206336\n",
       "3       WB   738734374912\n",
       "4       M1   747324309504"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visatype_df = create_visa_type(df_final_immigration, output_data)\n",
    "visatype_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Immigration Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visatype dim table needs to be created 1st before running \n",
    "\n",
    "def create_immigration(df, output_data):\n",
    "    \"\"\"This function creates an country dimension from the immigration and global land temperatures data.\n",
    "    \n",
    "    params \n",
    "        df: spark dataframe of immigration events\n",
    "        visa_type_df: spark dataframe of global land temperatures data.\n",
    "        output_data: path to write dimension dataframe to\n",
    "    \"\"\"\n",
    "\n",
    "    # get visa_type dimension\n",
    "    dim_df = get_visa_type_dimension(output_data).toPandas()\n",
    "    \n",
    "    @udf('string')\n",
    "    def get_visa_key(visa_type):\n",
    "        \"\"\"user defined function to get visa key\n",
    "        \n",
    "        params \n",
    "            visa_type: US non-immigrant visa type\n",
    "        \"\"\"\n",
    "        key_series = dim_df[dim_df['visatype']==visa_type]['visa_type_key']\n",
    "        \n",
    "        if not key_series.empty:\n",
    "            return str(key_series.iloc[0])\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # rename columns to align with data model\n",
    "    df = df.withColumnRenamed('cicid','record_id') \\\n",
    "            .withColumnRenamed('i94res', 'country_residence_code') \\\n",
    "            .withColumnRenamed('i94addr', 'state_code') \n",
    "    \n",
    "    # create visa_type key\n",
    "    df = df.withColumn('visa_type_key', get_visa_key('visatype'))\n",
    "    \n",
    "    \n",
    "    # removing visatype column because now moved into the visa_type dimension table \n",
    "    df = df.drop('visatype')\n",
    "    \n",
    "    # write dimension to parquet file\n",
    "    df.write.parquet(output_data + \"immigration_fact\", mode=\"overwrite\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Supplemental function to retrieve visa_type_dimension table used to execute get_visa_key udf within \n",
    "# create_immigration function above\n",
    "\n",
    "def get_visa_type_dimension(output_data):\n",
    "    return spark.read.parquet(output_data + \"visatype\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>country_residence_code</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>state_code</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visa_type_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243257</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>PHO</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>NY</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1972</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>DL</td>\n",
       "      <td>-359003515</td>\n",
       "      <td>00047</td>\n",
       "      <td>884763262976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289649</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>DET</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1957</td>\n",
       "      <td>10012016</td>\n",
       "      <td>M</td>\n",
       "      <td>DL</td>\n",
       "      <td>-1921760482</td>\n",
       "      <td>00582</td>\n",
       "      <td>369367187456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1498315</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>582</td>\n",
       "      <td>582</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016-04-08</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1976</td>\n",
       "      <td>10072016</td>\n",
       "      <td>F</td>\n",
       "      <td>Y4</td>\n",
       "      <td>-1459106882</td>\n",
       "      <td>00976</td>\n",
       "      <td>369367187456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2305457</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>SFR</td>\n",
       "      <td>2016-04-13</td>\n",
       "      <td>1</td>\n",
       "      <td>CA</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1974</td>\n",
       "      <td>07112016</td>\n",
       "      <td>M</td>\n",
       "      <td>KL</td>\n",
       "      <td>255357485</td>\n",
       "      <td>00605</td>\n",
       "      <td>738734374912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4702607</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>1</td>\n",
       "      <td>FL</td>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>1967</td>\n",
       "      <td>07232016</td>\n",
       "      <td>None</td>\n",
       "      <td>BA</td>\n",
       "      <td>-873770311</td>\n",
       "      <td>02037</td>\n",
       "      <td>884763262976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  i94yr  i94mon  i94cit  country_residence_code i94port  \\\n",
       "0     243257   2016       4     130                     130     PHO   \n",
       "1     289649   2016       4     245                     245     DET   \n",
       "2    1498315   2016       4     582                     582     SEA   \n",
       "3    2305457   2016       4     104                     104     SFR   \n",
       "4    4702607   2016       4     135                     135     ORL   \n",
       "\n",
       "      arrdate  i94mode state_code     depdate      ...       entdepa  entdepd  \\\n",
       "0  2016-04-02        1         NY  2016-04-07      ...             G        O   \n",
       "1  2016-04-02        1         GA  2016-04-11      ...             G        O   \n",
       "2  2016-04-08        1         FL  2016-04-16      ...             G        O   \n",
       "3  2016-04-13        1         CA  2016-04-21      ...             G        O   \n",
       "4  2016-04-25        1         FL  2016-04-28      ...             O        O   \n",
       "\n",
       "   matflag  biryear   dtaddto gender airline      admnum  fltno visa_type_key  \n",
       "0        M     1972  06302016      F      DL  -359003515  00047  884763262976  \n",
       "1        M     1957  10012016      M      DL -1921760482  00582  369367187456  \n",
       "2        M     1976  10072016      F      Y4 -1459106882  00976  369367187456  \n",
       "3        M     1974  07112016      M      KL   255357485  00605  738734374912  \n",
       "4        M     1967  07232016   None      BA  -873770311  02037  884763262976  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_fact_df = create_immigration(df_final_immigration, output_data)\n",
    "immigration_fact_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- record_id: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- country_residence_code: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: integer (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- depdate: date (nullable = true)\n",
      " |-- i94bir: integer (nullable = true)\n",
      " |-- i94visa: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- dtadfile: integer (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visa_type_key: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Data Quality Test(Source/Count check for completeness): Table Load Success Test\n",
    "\n",
    "Counting total # of records in all Dimension and Fact tables to confirm loading has been done correctly.\n",
    "\n",
    "Total # of records should correspond to the expected # during both data cleaning and table creation steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED 1st Data Quality test for immigration_fact table with 1,000 records found.\n",
      "PASSED 1st Data Quality test for visa_type_dim table with 10 records found.\n",
      "PASSED 1st Data Quality test for time_dim table with 1,000 records found.\n",
      "PASSED 1st Data Quality test for demographics_dim table with 2,875 records found.\n",
      "PASSED 1st Data Quality test for country_dim table with 91 records found.\n"
     ]
    }
   ],
   "source": [
    "# Code for this quality test is imported from etl_functions file with the function named \"quality_checks\"\n",
    "# df's here are finalized created during table creation\n",
    "\n",
    "table_dfs = {\n",
    "    'immigration_fact': immigration_fact_df,\n",
    "    'visa_type_dim': visatype_df,\n",
    "    'time_dim': time_df,\n",
    "    'demographics_dim': demographics_df,\n",
    "    'country_dim': country_df\n",
    "}\n",
    "for table_name, table_df in table_dfs.items():\n",
    "    # count quality check for table\n",
    "    etl_functions.quality_checks(table_df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Data Quality Test(Integrity Contraint): Primary Key Duplicate Check\n",
    "\n",
    "2nd test checks to make sure there are no duplicate primary keys or ID's in the dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: No duplicate IDs in time dim table.\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate ID entries in time dimension table\n",
    "# updated df in order to conver to panda view\n",
    "\n",
    "time_df_new = time_df.toPandas()\n",
    "time_df_new['id'].duplicated().any()\n",
    "\n",
    "if True:\n",
    "    print('PASSED: No duplicate IDs in time dim table.')\n",
    "else:\n",
    "    print('FAILED: Duplicate IDs found in time dim table.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: No duplicate IDs in demographics dim table.\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate ID entries in demographics dimension table\n",
    "demographics_df_new = demographics_df.toPandas()\n",
    "demographics_df_new['id'].duplicated().any()\n",
    "\n",
    "if True:\n",
    "    print('PASSED: No duplicate IDs in demographics dim table.')\n",
    "else:\n",
    "    print('FAILED: Duplicate IDs found in demographics dim table.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: No duplicate visa_type_keys in visatype dim table.\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate visa type key entries in visatype dimension table\n",
    "visatype_df_new = visatype_df.toPandas()\n",
    "visatype_df_new['visa_type_key'].duplicated().any()\n",
    "\n",
    "if True:\n",
    "    print('PASSED: No duplicate visa_type_keys in visatype dim table.')\n",
    "else:\n",
    "    print('FAILED:Duplicate visa_type_keys found in visatype dim table.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED: No duplicate country codes in country dim table.\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate country code entries in country dimension table\n",
    "country_df_new = country_df.toPandas()\n",
    "country_df_new['country_code'].duplicated().any()\n",
    "\n",
    "if True:\n",
    "    print('PASSED: No duplicate country codes in country dim table.')\n",
    "else:\n",
    "    print('FAILED: Duplicate country codes found in country dim table.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd Data Quality Test(Script Unit Test): Null Check on Primary Keys\n",
    "Test to confirm table creating scripts are performing correctly: where primary keys are created correctly, and in \n",
    "\n",
    "their right designated tables/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.createOrReplaceTempView(\"dim_country\")\n",
    "demographics_df.createOrReplaceTempView(\"dim_demographics\")\n",
    "time_df.createOrReplaceTempView(\"dim_time\")\n",
    "visatype_df.createOrReplaceTempView(\"dim_visatype\")\n",
    "immigration_fact_df.createOrReplaceTempView(\"fact_immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check for null values\n",
    "def nullValueCheck(spark_ctxt, tables_to_check):\n",
    "    \"\"\"\n",
    "    This function performs null value checks on specific columns of given tables received \\\n",
    "    as parameters and raises a ValueError exception when null values are encountered.\n",
    "    It receives the following parameters:\n",
    "    spark_ctxt: spark context where the data quality check is to be performed\n",
    "    tables_to_check: A dictionary containing (table, columns) pairs specifying for each table,\\\n",
    "    which column is to be checked for null values.   \n",
    "    \"\"\"  \n",
    "    for table in tables_to_check:\n",
    "        print(f\"Performing primary key null value check on table {table}...\")\n",
    "        for column in tables_to_check[table]:\n",
    "            returnedVal = spark_ctxt.sql(f\"\"\"SELECT COUNT(*) as nbr FROM {table} WHERE {column} IS NULL\"\"\")\n",
    "            if returnedVal.head()[0] > 0:\n",
    "                raise ValueError(f\"3rd Data quality check failed! Found NULL values in {column} column!\")\n",
    "        print(f\"Table {table} passed 3rd Data Quality Test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing primary key null value check on table fact_immigration...\n",
      "Table fact_immigration passed 3rd Data Quality Test.\n",
      "Performing primary key null value check on table dim_visatype...\n",
      "Table dim_visatype passed 3rd Data Quality Test.\n",
      "Performing primary key null value check on table dim_time...\n",
      "Table dim_time passed 3rd Data Quality Test.\n",
      "Performing primary key null value check on table dim_demographics...\n",
      "Table dim_demographics passed 3rd Data Quality Test.\n",
      "Performing primary key null value check on table dim_country...\n",
      "Table dim_country passed 3rd Data Quality Test.\n"
     ]
    }
   ],
   "source": [
    "tables_to_check = { 'fact_immigration' : ['record_id'], \"dim_visatype\":['visa_type_key'], 'dim_time':['arrdate'],\\\n",
    "                    'dim_demographics': ['City','state_code'],\\\n",
    "                    'dim_country':['country_code']}\n",
    "\n",
    "nullValueCheck(spark, tables_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Time Dimension Table Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">arrdate(Primary Key)</td><td class=\"tg-0pky\">Arrival Date into the US</td>\n",
    " <tr><td class=\"tg-0pky\">arrival_day</td><td class=\"tg-0pky\">Global average land temperature in celsius</td>\n",
    " <tr><td class=\"tg-0pky\">arrival_week</td><td class=\"tg-0pky\">95% confidence interval around the average</td>\n",
    " <tr><td class=\"tg-0pky\">arrival_month</td><td class=\"tg-0pky\">City Name</td>\n",
    " <tr><td class=\"tg-0pky\">arrival_year</td><td class=\"tg-0pky\">Country Name</td>\n",
    " <tr><td class=\"tg-0pky\">arrival_weekday</td><td class=\"tg-0pky\">Latitude of City</td>\n",
    " <tr><td class=\"tg-0pky\">id</td><td class=\"tg-0pky\">unique monotonically increasing id created</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Country Dimension Table Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">country_code(Primary Key)</td><td class=\"tg-0pky\">Unique country code</td>\n",
    " <tr><td class=\"tg-0pky\">country_name</td><td class=\"tg-0pky\">Name of country</td>\n",
    " <tr><td class=\"tg-0pky\">average_temperature</td><td class=\"tg-0pky\">Average temperature of country</td>\n",
    " <tr><td class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Demographics Dimension Table Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">state_code (Primary Key)</td><td class=\"tg-0pky\">US State of arrival</td>\n",
    " <tr><td class=\"tg-0pky\">city</td><td class=\"tg-0pky\">City Name</td>\n",
    " <tr><td class=\"tg-0pky\">state</td><td class=\"tg-0pky\">State of city</td>\n",
    " <tr><td class=\"tg-0pky\">median_age</td><td class=\"tg-0pky\">Median age of population</td>\n",
    " <tr><td class=\"tg-0pky\">male_population</td><td class=\"tg-0pky\">Male Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">female_population</td><td class=\"tg-0pky\">Female Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">total_population</td><td class=\"tg-0pky\">Total Population of city</td>\n",
    " <tr><td class=\"tg-0pky\">number_of_veterans</td><td class=\"tg-0pky\">Veteran Population in city</td>\n",
    " <tr><td class=\"tg-0pky\">foreign_born</td><td class=\"tg-0pky\">Population of residents not born in city</td>\n",
    " <tr><td class=\"tg-0pky\">average_household_size</td><td class=\"tg-0pky\">Average city household size</td>\n",
    " <tr><td class=\"tg-0pky\">race</td><td class=\"tg-0pky\">Traveler's race</td>\n",
    " <tr><td class=\"tg-0pky\">count</td><td class=\"tg-0pky\">Count of city's individual per race</td>\n",
    " <tr><td class=\"tg-0pky\">id</td><td class=\"tg-0pky\">Unique monotonically increasing id created</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Visa_type Dimension Table Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">visa_type_key(Primary Key)</td><td class=\"tg-0pky\">Unique country code</td>\n",
    " <tr><td class=\"tg-0pky\">country_name</td><td class=\"tg-0pky\">Name of country</td>\n",
    " <tr><td class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>Immigration Fact Table Data Dictionary</i></b>\n",
    "\n",
    "<table class=\"tg\" align=\"left\">\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\">Feature</th>\n",
    "    <th class=\"tg-0pky\">Description</th>\n",
    "  </tr>\n",
    " <tr><td class=\"tg-0pky\">record_id (cicid)</td><td class=\"tg-0pky\">Unique record ID</td>\n",
    " <tr><td class=\"tg-0pky\">i94yr</td><td class=\"tg-0pky\">4 digit year</td>\n",
    " <tr><td class=\"tg-0pky\">i94mon</td><td class=\"tg-0pky\">Numeric month</td>\n",
    " <tr><td class=\"tg-0pky\">i94cit</td><td class=\"tg-0pky\">3 digit code for traveler's birth country</td>\n",
    " <tr><td class=\"tg-0pky\">country_residence_code (i94res)</td><td class=\"tg-0pky\">3 digit code for traveler's country of residence </td>\n",
    " <tr><td class=\"tg-0pky\">i94port</td><td class=\"tg-0pky\">Port of admission</td>\n",
    " <tr><td class=\"tg-0pky\">arrdate</td><td class=\"tg-0pky\">Arrival Date into the US</td>\n",
    " <tr><td class=\"tg-0pky\">i94mode</td><td class=\"tg-0pky\">Mode of transportation; 1 = Air; 2 = Sea; 3 = Land; 9 = Unknown</td>\n",
    " <tr><td class=\"tg-0pky\">state_code (i94addr)</td><td class=\"tg-0pky\">US State of arrival</td>\n",
    " <tr><td class=\"tg-0pky\">depdate</td><td class=\"tg-0pky\">Departure Date from the US</td>\n",
    " <tr><td class=\"tg-0pky\">i94bir</td><td class=\"tg-0pky\">Birth Year</td>\n",
    " <tr><td class=\"tg-0pky\">i94visa</td><td class=\"tg-0pky\">Visa codes</td>\n",
    " <tr><td class=\"tg-0pky\">count</td><td class=\"tg-0pky\">Field used for summary statistics</td>\n",
    " <tr><td class=\"tg-0pky\">dtadfile</td><td class=\"tg-0pky\">Character Date Field - Date added to I-94 Files</td>\n",
    " <tr><td class=\"tg-0pky\">visapost</td><td class=\"tg-0pky\">Department of State where Visa was issued </td>\n",
    " <tr><td class=\"tg-0pky\">entdepa</td><td class=\"tg-0pky\">Arrival Flag</td>\n",
    " <tr><td class=\"tg-0pky\">entdepd</td><td class=\"tg-0pky\">Departure Flag</td>\n",
    " <tr><td class=\"tg-0pky\">matflag</td><td class=\"tg-0pky\">Match flag</td>\n",
    " <tr><td class=\"tg-0pky\">biryear</td><td class=\"tg-0pky\">4 digit year of birth</td>\n",
    " <tr><td class=\"tg-0pky\">dtaddto</td><td class=\"tg-0pky\">Character Date Field; Date to which admitted to U.S.</td>\n",
    " <tr><td class=\"tg-0pky\">gender</td><td class=\"tg-0pky\">Gender</td>\n",
    " <tr><td class=\"tg-0pky\">insnum</td><td class=\"tg-0pky\">INS number</td>\n",
    " <tr><td class=\"tg-0pky\">airline</td><td class=\"tg-0pky\">Arrival Airline</td>\n",
    " <tr><td class=\"tg-0pky\">admnum</td><td class=\"tg-0pky\">Admission Number</td>\n",
    " <tr><td class=\"tg-0pky\">fltno</td><td class=\"tg-0pky\">Arrival Airline Flight number</td>\n",
    " <tr><td class=\"tg-0pky\">visa_type_key</td><td class=\"tg-0pky\">Unique id for each visa issued</td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/i94_apr16_sub.sas7bdat',\n",
       " './data/i94_sep16_sub.sas7bdat',\n",
       " './data/i94_nov16_sub.sas7bdat',\n",
       " './data/i94_mar16_sub.sas7bdat',\n",
       " './data/i94_jun16_sub.sas7bdat',\n",
       " './data/i94_aug16_sub.sas7bdat',\n",
       " './data/i94_may16_sub.sas7bdat',\n",
       " './data/i94_jan16_sub.sas7bdat',\n",
       " './data/i94_oct16_sub.sas7bdat',\n",
       " './data/i94_jul16_sub.sas7bdat',\n",
       " './data/i94_feb16_sub.sas7bdat',\n",
       " './data/i94_dec16_sub.sas7bdat']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "copy_tree(\"../../data/18-83510-I94-Data-2016/\", \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
